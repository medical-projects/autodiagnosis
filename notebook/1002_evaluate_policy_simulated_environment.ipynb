{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate different policies in the simulated environment\n",
    "\n",
    "## Description of the simulated environment\n",
    "1. Goal: Detect terminal event with the smallest cost\n",
    "1. Label: {0, 1}, 0 indicates normal, 5 1's indicates terminal event\n",
    "1. Reponse: a time series composed of 0 and 1\n",
    "    1. Generate under a markov chain\n",
    "        1. $p(L_{t+1} = 0 |L_{t} = 0) = 0.9$\n",
    "        1. $p(L_{t+1} = 0 |L_{t} = 1) = 0.1$\n",
    "        1. $p(L_{t+1} = 1 |L_{t} = 0) = 1.0$\n",
    "        1. $p(L_{t+1} = 1 |L_{t} = 1) = 0.0$\n",
    "    1. The series terminate with 5 1's\n",
    "1. Time series measurements generated according to the label\n",
    "    1. 3 informative features\n",
    "        1. $1 \\pm \\epsilon$ if $L=1$\n",
    "        1. $-1 \\pm \\epsilon$ if $L=0$\n",
    "    1. 3 noisy features\n",
    "    1. Randomly introduced missingness to create incompleted dataset\n",
    "        1. missing value is encoder as $0$\n",
    "1. Size of Training + Val set: 5000\n",
    "\n",
    "    \n",
    "## Description of classifier for event forcasting \n",
    "1. A softmax that takes in\n",
    "    1. a state consisiting of measurements of the 5 most recent time steps and,\n",
    "    1. a feature importance vector\n",
    "        1. first three features have increasing importance\n",
    "        1. last three features have some closs to zero importance\n",
    "1. A Softmax output a probability of event occur at or after 5 time steps\n",
    "    \n",
    "\n",
    "## Description of the RL problem\n",
    "1. State: a state consisting of measurements of the 5 most recent time steps\n",
    "1. Actions: all possible measurement that can be done for the next time point\n",
    "    1. (6 measurements) x 2\n",
    "    1. For each measurement, the agent may choose to do it or not do it \n",
    "1. Rewards\n",
    "    1. A 6-dimensional vector, the reward of each measurement is assumped to be independent of reward of another measurement\n",
    "    1. Difference in cross entropy loss between an action vs no any measurement performed.\n",
    "\n",
    "\n",
    "## Evaluation in an online setting\n",
    "1. Agent observ state $s_t$\n",
    "1. Agent decide action $a_t$\n",
    "1. Environment generate next state $s_{t+1}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from arch.K_Tails_Dueling_DQN import KTailsDuelingDQN\n",
    "from simulated_patient_database import DummyDisease, DummyClassifier, SimulatedPatientDatabaseDiscrete\n",
    "from sim_observation_dummy_disease import ExperienceGeneratorMixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_actions(s, action_dim):\n",
    "    batch_size = len(s)\n",
    "    return np.random.randint(0, 2, (batch_size, action_dim))\n",
    "\n",
    "\n",
    "def get_random_informative_action(s, action_dim, useful_action_dim):\n",
    "    batch_size = len(s)\n",
    "    return np.concatenate((np.random.randint(0, 2, (batch_size, useful_action_dim)),\n",
    "                           np.zeros((batch_size, action_dim - useful_action_dim))), axis=1)\n",
    "\n",
    "\n",
    "def get_all_actions(s, action_dim):\n",
    "    batch_size = len(s)\n",
    "    return np.ones((batch_size, action_dim))\n",
    "\n",
    "\n",
    "def get_all_informative_actions(s, action_dim, useful_action_dim):\n",
    "    batch_size = len(s)\n",
    "    return np.concatenate((np.ones((batch_size, useful_action_dim)),\n",
    "                           np.zeros((batch_size, action_dim - useful_action_dim))), axis=1)\n",
    "\n",
    "def get_single_informative_actions(s, action_dim, indices):\n",
    "    batch_size = len(s)\n",
    "    a = np.zeros((batch_size, action_dim))\n",
    "    a[:, indices] = 1\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Evaluate policy')\n",
    "\n",
    "    parser.add_argument('--seed', type=int, default=0)\n",
    "    parser.add_argument('--reward_params', type=float, default=(105,))\n",
    "\n",
    "    parser.add_argument('--num_patients', type=int, default=500)\n",
    "\n",
    "    parser.add_argument('--early_detect_time', type=int, default=5)\n",
    "\n",
    "    parser.add_argument('--dataset_setting_path', type=str,\n",
    "                        default='../data/simulated_disease/1015_hyperparameters.pkl')\n",
    "    parser.add_argument('--data_keep_rate', type=float, default=0.9)\n",
    "\n",
    "    args = parser.parse_args([])\n",
    "\n",
    "    args.dqn_model_path_big_g = '../models/ktdqn-dummy1017-o30-a6-g0.99-m10000-nn1-2-64-lr1e-05-1e-05-0.5-' \\\n",
    "                                's64-5000-i20000-500-50-r(105,)-d0.9-r0/'\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate of death: 351/500\n"
     ]
    }
   ],
   "source": [
    "args = parse_args()\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "tf.set_random_seed(args.seed)\n",
    "\n",
    "dataset_setting = pickle.load(open(args.dataset_setting_path, 'rb'))\n",
    "\n",
    "classifier = DummyClassifier(num_useful_features=dataset_setting.num_useful_features,\n",
    "                             num_noisy_features=dataset_setting.num_noisy_features,\n",
    "                             obs_t_dim=dataset_setting.max_num_terminal_states,\n",
    "                             score_param_1=dataset_setting.score_param_1)\n",
    "\n",
    "disease = DummyDisease(feature_noise=dataset_setting.feature_noise,\n",
    "                       max_num_terminal_states=dataset_setting.max_num_terminal_states,\n",
    "                       num_useful_features=dataset_setting.num_useful_features,\n",
    "                       num_noisy_features=dataset_setting.num_noisy_features,\n",
    "                       num_datapoints_per_period=dataset_setting.num_datapoints_per_period,\n",
    "                       period_length=dataset_setting.period_length,\n",
    "                       min_periods=dataset_setting.min_periods, max_periods=dataset_setting.max_periods,\n",
    "                       keep_rate=args.data_keep_rate)\n",
    "\n",
    "patient_database = SimulatedPatientDatabaseDiscrete(obs_type=disease, num_patients=args.num_patients)\n",
    "\n",
    "print('Rate of death: {}/{}'.format(np.sum(patient_database.all_labels), args.num_patients))\n",
    "\n",
    "exp_generator = \\\n",
    "    ExperienceGeneratorMixed(patient_database=patient_database,\n",
    "                             classifier=classifier,\n",
    "                             early_detect_time=args.early_detect_time)\n",
    "\n",
    "def reward_func(cur_action, information_gain):\n",
    "    a = args.reward_params\n",
    "\n",
    "    information_gain = a * information_gain\n",
    "    action_cost = - cur_action\n",
    "    return information_gain + action_cost\n",
    "\n",
    "\n",
    "def evaluate_dqn_policy(dqn_model_path, get_action_random, threshold, e_greedy=1.0):\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "\n",
    "    dqn_hyperparam = pickle.load(open(dqn_model_path + 'hyperparameters.pkl', 'rb'))\n",
    "    dqn_results = pickle.load(open(dqn_model_path + 'results.pkl', 'rb'))\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    with tf.Session(config=config) as sess:\n",
    "        with tf.variable_scope('dqn', reuse=tf.AUTO_REUSE):\n",
    "            dqn = \\\n",
    "                KTailsDuelingDQN(variable_scope='dqn', state_dim=dqn_hyperparam.state_dim,\n",
    "                                 action_dim=dqn_hyperparam.action_dim,\n",
    "                                 gamma=dqn_hyperparam.gamma, lr=dqn_hyperparam.lr,\n",
    "                                 keep_prob=dqn_hyperparam.keep_prob,\n",
    "                                 reg_constant=dqn_hyperparam.reg_constant,\n",
    "                                 num_shared_all_layers=dqn_hyperparam.num_shared_all_layers,\n",
    "                                 num_shared_dueling_layers=dqn_hyperparam.num_shared_dueling_layers,\n",
    "                                 num_hidden_units=dqn_hyperparam.num_hidden_units,\n",
    "                                 replace_target_batch=dqn_hyperparam.replace_target_batch,\n",
    "                                 memory_size=dqn_hyperparam.memory_size, log=None)\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, dqn_model_path + 'model-%d' % dqn_results['best_model_idx'])\n",
    "\n",
    "        get_action = lambda s: dqn.get_best_actions(sess=sess, s=s) if np.random.rand() <= e_greedy \\\n",
    "            else get_action_random(s=s)\n",
    "\n",
    "        cur_state, actions = exp_generator.evaluate_with_deterministic_statte(get_action=get_action)\n",
    "\n",
    "        print(actions)\n",
    "\n",
    "        avg_reward, avg_action, accuracy = exp_generator.evaluate(get_action=get_action, reward_func=reward_func,\n",
    "                                                                  threshold=threshold)\n",
    "\n",
    "        # print('Average reward: {}, Avg action: {}'.format(avg_reward, avg_action))\n",
    "        return avg_reward, avg_action, accuracy\n",
    "\n",
    "\n",
    "def evaluate_easy_policy(get_action, threshold):\n",
    "    avg_reward, avg_action, accuracy = exp_generator.evaluate(get_action=get_action, reward_func=reward_func,\n",
    "                                                              threshold=threshold)\n",
    "\n",
    "    # print('Average reward: {}, Avg action: {}'.format(avg_reward, avg_action))\n",
    "    return avg_reward, avg_action, accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_action_random = lambda s: get_random_informative_action(s, action_dim=disease.num_features,\n",
    "                                                            useful_action_dim=disease.num_useful_features)\n",
    "get_action_all = lambda s: get_all_informative_actions(s, action_dim=disease.num_features,\n",
    "                                                      useful_action_dim=disease.num_useful_features)\n",
    "get_action_single0 = lambda s: get_single_informative_actions(s, action_dim=disease.num_features, indices=[0])\n",
    "get_action_single1 = lambda s: get_single_informative_actions(s, action_dim=disease.num_features, indices=[1])\n",
    "get_action_single2 = lambda s: get_single_informative_actions(s, action_dim=disease.num_features, indices=[2])\n",
    "get_action_single12 = lambda s: get_single_informative_actions(s, action_dim=disease.num_features, indices=[1, 2])\n",
    "get_action_single02 = lambda s: get_single_informative_actions(s, action_dim=disease.num_features, indices=[0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished: 0/500\n",
      "finished: 10/500\n",
      "finished: 20/500\n",
      "finished: 30/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/maimingj/projects/autodiagnosis/simulated_database/sim_observation_dummy_disease.py:374: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = information_gain_true / information_gain_sum\n",
      "/h/maimingj/projects/autodiagnosis/simulated_database/sim_observation_dummy_disease.py:374: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ratio = information_gain_true / information_gain_sum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished: 40/500\n",
      "finished: 50/500\n",
      "finished: 60/500\n",
      "finished: 70/500\n",
      "finished: 80/500\n",
      "finished: 90/500\n",
      "finished: 100/500\n",
      "finished: 110/500\n",
      "finished: 120/500\n",
      "finished: 130/500\n",
      "finished: 140/500\n",
      "finished: 150/500\n",
      "finished: 160/500\n",
      "finished: 170/500\n",
      "finished: 180/500\n",
      "finished: 190/500\n",
      "finished: 200/500\n",
      "finished: 210/500\n",
      "finished: 220/500\n",
      "finished: 230/500\n",
      "finished: 240/500\n",
      "finished: 250/500\n",
      "finished: 260/500\n",
      "finished: 270/500\n",
      "finished: 280/500\n",
      "finished: 290/500\n",
      "finished: 300/500\n",
      "finished: 310/500\n",
      "finished: 320/500\n",
      "finished: 330/500\n",
      "finished: 340/500\n",
      "finished: 350/500\n",
      "finished: 360/500\n",
      "finished: 370/500\n",
      "finished: 380/500\n",
      "finished: 390/500\n",
      "finished: 400/500\n",
      "finished: 410/500\n",
      "finished: 420/500\n",
      "finished: 430/500\n",
      "finished: 440/500\n",
      "finished: 450/500\n",
      "finished: 460/500\n",
      "finished: 470/500\n",
      "finished: 480/500\n",
      "finished: 490/500\n",
      "finished: 0/500\n",
      "finished: 10/500\n",
      "finished: 20/500\n",
      "finished: 30/500\n",
      "finished: 40/500\n",
      "finished: 50/500\n",
      "finished: 60/500\n",
      "finished: 70/500\n",
      "finished: 80/500\n",
      "finished: 90/500\n",
      "finished: 100/500\n",
      "finished: 110/500\n",
      "finished: 120/500\n",
      "finished: 130/500\n",
      "finished: 140/500\n",
      "finished: 150/500\n",
      "finished: 160/500\n",
      "finished: 170/500\n",
      "finished: 180/500\n",
      "finished: 190/500\n",
      "finished: 200/500\n",
      "finished: 210/500\n",
      "finished: 220/500\n",
      "finished: 230/500\n",
      "finished: 240/500\n",
      "finished: 250/500\n",
      "finished: 260/500\n",
      "finished: 270/500\n",
      "finished: 280/500\n",
      "finished: 290/500\n",
      "finished: 300/500\n",
      "finished: 310/500\n",
      "finished: 320/500\n",
      "finished: 330/500\n",
      "finished: 340/500\n",
      "finished: 350/500\n",
      "finished: 360/500\n",
      "finished: 370/500\n",
      "finished: 380/500\n",
      "finished: 390/500\n",
      "finished: 400/500\n",
      "finished: 410/500\n",
      "finished: 420/500\n",
      "finished: 430/500\n",
      "finished: 440/500\n",
      "finished: 450/500\n",
      "finished: 460/500\n",
      "finished: 470/500\n",
      "finished: 480/500\n",
      "finished: 490/500\n",
      "finished: 0/500\n",
      "finished: 10/500\n",
      "finished: 20/500\n",
      "finished: 30/500\n",
      "finished: 40/500\n",
      "finished: 50/500\n",
      "finished: 60/500\n",
      "finished: 70/500\n",
      "finished: 80/500\n",
      "finished: 90/500\n",
      "finished: 100/500\n",
      "finished: 110/500\n",
      "finished: 120/500\n",
      "finished: 130/500\n",
      "finished: 140/500\n",
      "finished: 150/500\n",
      "finished: 160/500\n",
      "finished: 170/500\n",
      "finished: 180/500\n",
      "finished: 190/500\n",
      "finished: 200/500\n",
      "finished: 210/500\n",
      "finished: 220/500\n",
      "finished: 230/500\n",
      "finished: 240/500\n",
      "finished: 250/500\n",
      "finished: 260/500\n",
      "finished: 270/500\n",
      "finished: 280/500\n",
      "finished: 290/500\n",
      "finished: 300/500\n",
      "finished: 310/500\n",
      "finished: 320/500\n",
      "finished: 330/500\n",
      "finished: 340/500\n",
      "finished: 350/500\n",
      "finished: 360/500\n",
      "finished: 370/500\n",
      "finished: 380/500\n",
      "finished: 390/500\n",
      "finished: 400/500\n",
      "finished: 410/500\n",
      "finished: 420/500\n",
      "finished: 430/500\n",
      "finished: 440/500\n",
      "finished: 450/500\n",
      "finished: 460/500\n",
      "finished: 470/500\n",
      "finished: 480/500\n",
      "finished: 490/500\n",
      "finished: 0/500\n",
      "finished: 10/500\n",
      "finished: 20/500\n",
      "finished: 30/500\n",
      "finished: 40/500\n",
      "finished: 50/500\n",
      "finished: 60/500\n",
      "finished: 70/500\n",
      "finished: 80/500\n",
      "finished: 90/500\n",
      "finished: 100/500\n",
      "finished: 110/500\n",
      "finished: 120/500\n",
      "finished: 130/500\n",
      "finished: 140/500\n",
      "finished: 150/500\n",
      "finished: 160/500\n",
      "finished: 170/500\n",
      "finished: 180/500\n",
      "finished: 190/500\n",
      "finished: 200/500\n",
      "finished: 210/500\n",
      "finished: 220/500\n",
      "finished: 230/500\n",
      "finished: 240/500\n",
      "finished: 250/500\n",
      "finished: 260/500\n",
      "finished: 270/500\n",
      "finished: 280/500\n",
      "finished: 290/500\n",
      "finished: 300/500\n",
      "finished: 310/500\n",
      "finished: 320/500\n",
      "finished: 330/500\n",
      "finished: 340/500\n",
      "finished: 350/500\n",
      "finished: 360/500\n",
      "finished: 370/500\n",
      "finished: 380/500\n",
      "finished: 390/500\n",
      "finished: 400/500\n",
      "finished: 410/500\n",
      "finished: 420/500\n",
      "finished: 430/500\n",
      "finished: 440/500\n",
      "finished: 450/500\n",
      "finished: 460/500\n",
      "finished: 470/500\n",
      "finished: 480/500\n",
      "finished: 490/500\n",
      "finished: 0/500\n",
      "finished: 10/500\n",
      "finished: 20/500\n",
      "finished: 30/500\n",
      "finished: 40/500\n",
      "finished: 50/500\n",
      "finished: 60/500\n",
      "finished: 70/500\n",
      "finished: 80/500\n",
      "finished: 90/500\n",
      "finished: 100/500\n",
      "finished: 110/500\n",
      "finished: 120/500\n",
      "finished: 130/500\n",
      "finished: 140/500\n",
      "finished: 150/500\n",
      "finished: 160/500\n",
      "finished: 170/500\n",
      "finished: 180/500\n",
      "finished: 190/500\n",
      "finished: 200/500\n",
      "finished: 210/500\n",
      "finished: 220/500\n",
      "finished: 230/500\n",
      "finished: 240/500\n",
      "finished: 250/500\n",
      "finished: 260/500\n",
      "finished: 270/500\n",
      "finished: 280/500\n",
      "finished: 290/500\n",
      "finished: 300/500\n",
      "finished: 310/500\n",
      "finished: 320/500\n",
      "finished: 330/500\n",
      "finished: 340/500\n",
      "finished: 350/500\n",
      "finished: 360/500\n",
      "finished: 370/500\n",
      "finished: 380/500\n",
      "finished: 390/500\n",
      "finished: 400/500\n",
      "finished: 410/500\n",
      "finished: 420/500\n",
      "finished: 430/500\n",
      "finished: 440/500\n",
      "finished: 450/500\n",
      "finished: 460/500\n",
      "finished: 470/500\n",
      "finished: 480/500\n",
      "finished: 490/500\n",
      "finished: 0/500\n",
      "finished: 10/500\n",
      "finished: 20/500\n",
      "finished: 30/500\n",
      "finished: 40/500\n",
      "finished: 50/500\n",
      "finished: 60/500\n",
      "finished: 70/500\n",
      "finished: 80/500\n",
      "finished: 90/500\n",
      "finished: 100/500\n",
      "finished: 110/500\n",
      "finished: 120/500\n",
      "finished: 130/500\n",
      "finished: 140/500\n",
      "finished: 150/500\n",
      "finished: 160/500\n",
      "finished: 170/500\n",
      "finished: 180/500\n",
      "finished: 190/500\n",
      "finished: 200/500\n",
      "finished: 210/500\n",
      "finished: 220/500\n",
      "finished: 230/500\n",
      "finished: 240/500\n",
      "finished: 250/500\n",
      "finished: 260/500\n",
      "finished: 270/500\n",
      "finished: 280/500\n",
      "finished: 290/500\n",
      "finished: 300/500\n",
      "finished: 310/500\n",
      "finished: 320/500\n",
      "finished: 330/500\n",
      "finished: 340/500\n",
      "finished: 350/500\n",
      "finished: 360/500\n",
      "finished: 370/500\n",
      "finished: 380/500\n",
      "finished: 390/500\n",
      "finished: 400/500\n",
      "finished: 410/500\n",
      "finished: 420/500\n",
      "finished: 430/500\n",
      "finished: 440/500\n",
      "finished: 450/500\n",
      "finished: 460/500\n",
      "finished: 470/500\n",
      "finished: 480/500\n",
      "finished: 490/500\n",
      "finished: 0/500\n",
      "finished: 10/500\n",
      "finished: 20/500\n",
      "finished: 30/500\n",
      "finished: 40/500\n",
      "finished: 50/500\n",
      "finished: 60/500\n",
      "finished: 70/500\n",
      "finished: 80/500\n",
      "finished: 90/500\n",
      "finished: 100/500\n",
      "finished: 110/500\n",
      "finished: 120/500\n",
      "finished: 130/500\n",
      "finished: 140/500\n",
      "finished: 150/500\n",
      "finished: 160/500\n",
      "finished: 170/500\n",
      "finished: 180/500\n",
      "finished: 190/500\n",
      "finished: 200/500\n",
      "finished: 210/500\n",
      "finished: 220/500\n",
      "finished: 230/500\n",
      "finished: 240/500\n",
      "finished: 250/500\n",
      "finished: 260/500\n",
      "finished: 270/500\n",
      "finished: 280/500\n",
      "finished: 290/500\n",
      "finished: 300/500\n",
      "finished: 310/500\n",
      "finished: 320/500\n",
      "finished: 330/500\n",
      "finished: 340/500\n",
      "finished: 350/500\n",
      "finished: 360/500\n",
      "finished: 370/500\n",
      "finished: 380/500\n",
      "finished: 390/500\n",
      "finished: 400/500\n",
      "finished: 410/500\n",
      "finished: 420/500\n",
      "finished: 430/500\n",
      "finished: 440/500\n",
      "finished: 450/500\n",
      "finished: 460/500\n",
      "finished: 470/500\n",
      "finished: 480/500\n",
      "finished: 490/500\n"
     ]
    }
   ],
   "source": [
    "resules = [evaluate_easy_policy(get_action=get_action_random, threshold=threshold), \n",
    "           evaluate_easy_policy(get_action=get_action_all, threshold=threshold),\n",
    "           evaluate_easy_policy(get_action=get_action_single0, threshold=threshold),\n",
    "           evaluate_easy_policy(get_action=get_action_single1, threshold=threshold),\n",
    "           evaluate_easy_policy(get_action=get_action_single2, threshold=threshold),\n",
    "           evaluate_easy_policy(get_action=get_action_single12, threshold=threshold),\n",
    "          evaluate_easy_policy(get_action=get_action_single02, threshold=threshold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Result: 0\n",
      "rew mean -47.11242196928637\n",
      "rew std 52.449573838453354\n",
      "act freq 0.2486314768782416\n",
      "accuracy 0.376\n",
      "\n",
      " Result: 1\n",
      "rew mean -84.74966932511042\n",
      "rew std 86.19073000693241\n",
      "act freq 0.5\n",
      "accuracy 0.968\n",
      "\n",
      " Result: 2\n",
      "rew mean -20.047109724753007\n",
      "rew std 28.526034222166786\n",
      "act freq 0.16666666666666663\n",
      "accuracy 0.298\n",
      "\n",
      " Result: 3\n",
      "rew mean -20.59467829610527\n",
      "rew std 32.793269509738\n",
      "act freq 0.16666666666666663\n",
      "accuracy 0.298\n",
      "\n",
      " Result: 4\n",
      "rew mean -21.124063289162738\n",
      "rew std 37.28632422412663\n",
      "act freq 0.16666666666666663\n",
      "accuracy 0.298\n",
      "\n",
      " Result: 5\n",
      "rew mean -48.503695470879954\n",
      "rew std 60.96289658319845\n",
      "act freq 0.33333333333333326\n",
      "accuracy 0.938\n",
      "\n",
      " Result: 6\n",
      "rew mean -50.00745213809427\n",
      "rew std 58.570423366589026\n",
      "act freq 0.33333333333333326\n",
      "accuracy 0.662\n"
     ]
    }
   ],
   "source": [
    "for i, (r, a, acc) in enumerate(resules):\n",
    "    print('\\n Result: {}'.format(i))\n",
    "    print('rew mean', np.mean(np.sum(r, axis=1), axis=0))\n",
    "    print('rew std',  np.std(np.sum(r, axis=1), axis=0))\n",
    "    print('act freq', np.mean(a))\n",
    "    print('accuracy', np.mean(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models/ktdqn-dummy1017-o30-a6-g0.99-m10000-nn1-2-64-lr1e-05-1e-05-0.5-s64-5000-i20000-500-50-r(105,)-d0.9-r0/model-42\n",
      "[[0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 1 1 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 1 1 0 0 0]\n",
      " [0 1 1 0 0 0]\n",
      " [0 1 1 0 0 0]\n",
      " [0 1 1 0 0 0]]\n",
      "finished: 0/500\n",
      "finished: 10/500\n",
      "finished: 20/500\n",
      "finished: 30/500\n",
      "finished: 40/500\n",
      "finished: 50/500\n",
      "finished: 60/500\n",
      "finished: 70/500\n",
      "finished: 80/500\n",
      "finished: 90/500\n",
      "finished: 100/500\n",
      "finished: 110/500\n",
      "finished: 120/500\n",
      "finished: 130/500\n"
     ]
    }
   ],
   "source": [
    "res = evaluate_dqn_policy(dqn_model_path=args.dqn_model_path_big_g, get_action_random=get_action_random, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, a, acc = res\n",
    "print('rew mean', np.mean(np.sum(r, axis=1), axis=0))\n",
    "print('rew std',  np.std(np.sum(r, axis=1), axis=0))\n",
    "print('act freq', np.mean(a))\n",
    "print('acc', np.mean(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
